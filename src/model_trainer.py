# üìÑ src/model_trainer.py

import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    mean_squared_error,
)
import joblib


def train_models(data_path, output_dir):
    print("üì• Loading engineered dataset...")
    df = pd.read_csv(data_path)

    # ---------------- Clean data ----------------
    # Drop rows with missing target or close
    df.dropna(subset=["target", "close"], inplace=True)

    # Define features for Logistic Regression (exclude 'close')
    features = [
        "open", "high", "low", "volume",
        "MA5", "MA10", "MA20", "Volatility", "RSI",
        "lag_close_1", "lag_pct_1"
    ]

    # Replace infinities and fill NaN with 0
    df[features] = df[features].replace([float('inf'), -float('inf')], pd.NA).fillna(0)

    # ---------------- Logistic Regression ----------------
    print("\n‚öôÔ∏è Training Logistic Regression model (for UP/DOWN movement)...")
    X_log = df[features]
    y_log = df["target"]

    X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(
        X_log, y_log, test_size=0.2, random_state=42, stratify=y_log
    )

    log_model = LogisticRegression(max_iter=1000)
    log_model.fit(X_train_log, y_train_log)
    y_pred_log = log_model.predict(X_test_log)

    # Metrics
    cm = confusion_matrix(y_test_log, y_pred_log)
    acc = accuracy_score(y_test_log, y_pred_log)
    prec = precision_score(y_test_log, y_pred_log)
    rec = recall_score(y_test_log, y_pred_log)

    print("\nüìä Confusion Matrix (Logistic Regression):")
    print(cm)
    print(f"‚úÖ Accuracy: {acc:.4f}")
    print(f"‚úÖ Precision: {prec:.4f}")
    print(f"‚úÖ Recall: {rec:.4f}")

    # ---------------- Linear Regression ----------------
    print("\n‚öôÔ∏è Training Linear Regression model (for price prediction)...")

    X_lin = df[features]
    y_lin = df["close"]

    X_lin = X_lin.replace([float('inf'), -float('inf')], pd.NA).fillna(0)

    X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(
        X_lin, y_lin, test_size=0.2, random_state=42
    )

    lin_model = LinearRegression()
    lin_model.fit(X_train_lin, y_train_lin)
    y_pred_lin = lin_model.predict(X_test_lin)

    mse = mean_squared_error(y_test_lin, y_pred_lin)
    print(f"\nüí∞ Linear Regression MSE: {mse:.6f}")

    # ---------------- Save models ----------------
    os.makedirs(output_dir, exist_ok=True)
    joblib.dump(log_model, os.path.join(output_dir, "logistic_model.pkl"))
    joblib.dump(lin_model, os.path.join(output_dir, "linear_model.pkl"))
    print(f"\nüíæ Models saved successfully to: {output_dir}")

    print("\n‚úÖ Training completed successfully.\n")


if __name__ == "__main__":
    # Use relative paths for flexibility
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(base_dir, "..", "data")
    model_dir = os.path.join(base_dir, "..", "models")

    # Prefer smaller dataset if available
    sample_data_path = os.path.join(data_dir, "engineered_stock_data_sample.csv")
    full_data_path = os.path.join(data_dir, "engineered_stock_data.csv")

    if os.path.exists(sample_data_path):
        data_path = sample_data_path
        print("üìÅ Using lightweight sample dataset for faster training.")
    elif os.path.exists(full_data_path):
        data_path = full_data_path
        print("‚ö†Ô∏è Using full dataset (large file). May take longer.")
    else:
        raise FileNotFoundError("‚ùå No dataset found in the 'data/' folder.")

    train_models(data_path, model_dir)
